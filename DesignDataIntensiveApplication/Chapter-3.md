# Storage and Retrieval

## Data structure
We only discuss the key value pair data.
### Log-structured sorted tree
#### Naive workflow
1. Always append new entry into the file sequentially like a log file.
2. Do NOT update existing entry. If an update/delete is needed, add a new entry with a marker.
3. There is only a single writer. Each write will be done in memory. Once the total writes in the memory exceeding a limit, those records will be converted as a segment and moved to the file system. In that case, we refer that file as a **segment**.
    * This is why the databse is concurrent friendly as all write requests are queued before sending to the single writer.
    * This is also a bottle neck of the writing performance. 
4. There are multiple readers at the same time but those readers will not directly reading from the segment. They will be either reading from the memory or from a merged file which merges the segments.
5. The merged file is generated by a merge processor in the background and the processor only fetches the latest value of each entry and update that value. Update/delete will also be applied during the merge process.
    * This is also why we see a delay when we conduct delete/update operation in the ElasticSearch which is also based on LSM tree. The reason is that the udpate/delete only happens during merging process.
    * A lot of I/O resources needed in the backgorund.
#### Optimizations
1. Sort the entry and merge blocks
    * When inserting to the memory, use a tree structure so that it's sorted at craetion time. When we move it to the file system (generate as a segment), it's also sorted.
    * Sort each entry in each segment and conduct a merge sort across different segments. See page 76 for example.
    * In case of sparse index, we can merge some continuous keys into the same block so that we can either jump those keys easily or locate those keys in the block easily.
2. Memory crash
    * Always write to the file in a file ssytem before inserting to the memory
    * The guarantee of sequential writes also ease the burdern of picking up partial changes.
3. Key lookup: bloom filter which is a memory-efficient data structure for approximating the contents of a set.
    * In [bloom filter](https://en.wikipedia.org/wiki/Bloom_filter), false negatives will never happens. This mean if a key does not exist in the DB, we will always say it does not exist.

### B-tree
In LSM tree, a segment is generated once the data in memory exceeds a limit. However, in B-tree, the whole memory is splitted into multiple equal parts and each part is referenced based on the memory address of the block or a location, similar to the pointer in C++. And each chunk has a reference to the next chunk, similar to the linkedlist.

One page is designated as the root of the B-treae. Whenever we want to look up a key in the index, we start from that root node. Each chunk/page contains several continuous keys and references to the child pages. Each child is responsible for a continuous range of keys and the keys between the references indicate where the boundaries between those ranges lie. See example at page 80. Eventually we get to the page which only contains individual keys. The leaf node of the tree stores the actual data at each address.

The number of references of child noeds (i.e. number of child nodes) is called the *branch factor*. 

If we want to update the value of an existing key in the tree:
  1. we need to search for the leaf node containing that key
  2. Change the value of that page
  3. Write the page back to the disk
    
If we want to add a new key into the tree: See example at page 81.
  1. we need to find the page whose range encompasses the new key
  2. add the new key to that page
  3. If the space is not enough to accommodate that new key in that page. Things become trickier. 
    1. We need to split that page into two half-full pages
    2. The parent page should also be updated because the key range is changed as well.

The above update operation ensures the tree is balanced and hence N keys will always has a depth of O(lgN) and ensures the query speed.

#### Optimization
* Concurrency control: a lock is required when updating the tree
* It is assumed that we will only overwrite the value of each page and keep the key (i.e. memory address) of the page as the same. Think of overwriting a page on disk as an actual hardware oepartion. On a magnetic hard drive, this means moving the disk head to the right place, waiting for the right position on the spinning platter to come around and then overwriting the appropriate section with new data.
* Write ahead to the file system before upadting the tree, similar to LSM tree.
* Have additional pointers to the tree. For example, each leaf node can have pointer to its sibling nodes.

### Other indexes:
1. Value itself is the index
2. ReferenceID as the index
3. Composited values as the index
4. Fuzzy index, like a trie.

## Tarnsaction processing (OLTP) and analytics processing (OLAP)
### Main difference:
1. READ: OLTP has a few per key. OLAP has to aggregate a large number of records.
2. WRITE: OLTP has a randome write request and low-latency requirement. OLAP has bulk import or event stream.
3. User: OLTP is for customers. OLAP is for business analytst.
4. Data representation: OLTP: latest state of the data. OLAP: historical event over time.
5. Size: GB/TB versus TB/PB

### Star schema
The star schema arises from the fact that when the table relationships are visualized, the fact table is in the middle, surrounded by its dimension tables and the connections to these table are like the rays of star.
 
The advantage of the star schema is that it can 
1. avoid conflict/multiple write in the same table
2. decouple each dimension of the data
3. support highly customization of each dimension because we can have a separate table for a dimension and include whatever we need for a dimension. For example, a date can be a string if it is put in the fact table but if it is in a separate table, we can add the holiday attribute to the date dimension.
4. faster query and aggregation based on different dimensions
5. The fact table can be an event which represents the aggregation of multiple data record from OLTP.
    
## Column-oriented storage
The naive understanding of storing records in the database can be saving each record as a row in a file. When we do a query, essentially we still need to sacn each row to find the right row. This is still time-consuming if we only need to query a few columns.

But for the column-oriented storage, the values at each column of the record are stored as a separa file and each file has the same order. Based on this, we only need to check the data from the files we need if we only need a few columns in a query.

### Optimization
1. Column compression to save disk space: bitmap encoding. See example at page 98.
2. Impose an order in one column file and apply the same sortings to the other column files. This is where we generate the primary index and second index.
